{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dd36dc-1a3e-4a32-9455-928769f9d72a",
   "metadata": {},
   "source": [
    "## RNN, LSTM, and GRU\n",
    "**Code by**: Noor de Bruijn \\\n",
    "**Date**: Thursday, November 6th 2025 \\\n",
    "**Task**: Forecasting of electricity consumption (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b9af995c-de8b-415d-a8c5-9e71ff191a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969acccf-f61c-4f4b-b9a0-3adc7f3c9718",
   "metadata": {},
   "source": [
    "#### I. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "396cc3fa-01c4-43a7-88a8-b765a000f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"LD2011_2014.txt\", sep=';', index_col=0, parse_dates=True, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13eff0c-d7aa-4043-ab4b-a45e7a699513",
   "metadata": {},
   "source": [
    "#### II. Create datatime and year variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "625fb48f-7fc0-45c0-8959-8328dec4919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index()\n",
    "dataset.rename(columns={\"index\": \"Datetime\"}, inplace=True)\n",
    "dataset[\"year\"] = dataset[\"Datetime\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d792cc22-2983-4467-9590-aefbb6260550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2011    0\n",
      "2012    0\n",
      "2013    0\n",
      "2014    0\n",
      "2015    0\n",
      "Name: MT_001, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selection = dataset[['Datetime', 'MT_001', 'year']]\n",
    "missing_per_year = selection.groupby('year')['MT_001'].apply(lambda x: x.isna().sum())\n",
    "print(missing_per_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca9b9e-5301-4233-9ef6-8e974b199744",
   "metadata": {},
   "source": [
    "#### III. Split data in train_data and test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b680e29-5dbe-46b7-8ddd-6c7c844c70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105215\n",
      "35040\n"
     ]
    }
   ],
   "source": [
    "#Split data by year to get training_data (2011-2013) and test_data (2014)\n",
    "train_data = dataset[dataset[\"year\"].between(2011, 2013)][[\"Datetime\", \"MT_001\"]].copy()\n",
    "train_data.rename(columns={\"MT_001\": \"Consumption\"}, inplace=True)\n",
    "print(len(train_data))\n",
    "\n",
    "test_data = dataset[dataset[\"year\"] == 2014][[\"Datetime\", \"MT_001\"]].copy()\n",
    "test_data.rename(columns={\"MT_001\": \"Consumption\"}, inplace=True)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3c056-4a9a-4c03-b0e7-02ed9b3dcf5d",
   "metadata": {},
   "source": [
    "#### IV. Count missing values in Consumption column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da4aa79b-875c-43a0-8597-da987b478dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Consumption'].isna().sum())\n",
    "print(test_data['Consumption'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b0812-9725-4511-9d48-91c0b3f5fd8b",
   "metadata": {},
   "source": [
    "#### V. Make sure type = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9c741a22-cf33-4bb2-9aa9-bd857e93646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Consumption'] = train_data['Consumption'].str.replace(',', '.').astype(float)\n",
    "test_data['Consumption'] = test_data['Consumption'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd346f-2de8-48cc-b86f-b3209364eb4e",
   "metadata": {},
   "source": [
    "#### VI. Create TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bf4e97d-1bcb-43e5-9358-dfc655ba466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105119, 96) (105119,)\n",
      "(34944, 96) (34944,)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 96\n",
    "\n",
    "def create_sequences(df, seq_length):\n",
    "    xs, xy = [], []\n",
    "    for i in range(len(df) - seq_length):\n",
    "        x = df.iloc[i:(i+seq_length), 1]\n",
    "        y = df.iloc[i+seq_length, 1]\n",
    "        xs.append(x)\n",
    "        xy.append(y)\n",
    "    return np.array(xs), np.array(xy)\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "#Convert to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "#Create TensorDataset\n",
    "dataset_train = TensorDataset(\n",
    "    torch.from_numpy(X_train),\n",
    "    torch.from_numpy(y_train),\n",
    ")\n",
    "\n",
    "dataset_test = TensorDataset(\n",
    "    torch.from_numpy(X_test),\n",
    "    torch.from_numpy(y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8712c6-40d5-4743-ab44-db1afe7d2a34",
   "metadata": {},
   "source": [
    "#### VII. Create train_loader and test_loader\n",
    "**Important**: We do not shuffle the data here. We are working with a dataset where there is a temporal dependency. Shuffling sequences randomly could leak future information into the model or break the natural order it needs to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "507a873f-88af-402e-b3ea-a654c27589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train_loader\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b15c8a6-0ecd-4b2f-aeb4-1e8e016d4105",
   "metadata": {},
   "source": [
    "#### Define and run RNN\n",
    "Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b1f98bff-c633-4734-852c-e929b7fda994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size = 1,\n",
    "            hidden_size = 32,\n",
    "            num_layers = 2,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "35e2f51d-b27b-476f-8f1a-181f8df3c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "RNN_model = RNN()\n",
    "\n",
    "#Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.Adam(RNN_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0e68ef40-7f25-4e9f-90e2-b70ad434ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|█████████████████████████| 26280/26280 [02:41<00:00, 162.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 5.5845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Device set-up\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RNN_model = RNN_model.to(device)\n",
    "\n",
    "#Training the RNN\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #Set to training mode\n",
    "    RNN_model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X_batch = X_batch.unsqueeze(-1).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = RNN_model(X_batch)\n",
    "\n",
    "        #Calculate loss\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #Update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        #Track loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3406fce6-bba3-47e2-a9a3-739a652354e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|███████████████████████████| 8736/8736 [00:09<00:00, 911.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 4.31719970703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation loop\n",
    "#Metrics tracking\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "RNN_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X_batch = X_batch.unsqueeze(-1).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = RNN_model(X_batch)\n",
    "\n",
    "        mse(outputs.squeeze(), y_batch)\n",
    "\n",
    "print(f\"Test MSE: {mse.compute()}\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31420b-477a-44cb-862c-e748fd566543",
   "metadata": {},
   "source": [
    "#### II. LSTM\n",
    "Long Short-Term Memory cell\n",
    "1. **Forget gate**: What to remove from long-term memory.\n",
    "2. **Input gate**: What to save to long-term memory.\n",
    "3. **Output gate**: What to return at the current time step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feebe9a-42b3-4f97-b85c-40a9fddba567",
   "metadata": {},
   "source": [
    "#### Define and run LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a662c4e-7d10-4a21-95f4-098a9ed8b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = 32,\n",
    "            num_layers = 2,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        c0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68b73b1c-849c-4e65-88a0-a91a22d99226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "LSTM_model = LSTM(input_size=1)\n",
    "\n",
    "#Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.Adam(LSTM_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "deb8d59d-63b5-4061-80b4-0053bd057054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████████████████████| 26280/26280 [07:21<00:00, 59.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 5.6527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Device set-up\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LSTM_model = LSTM_model.to(device)\n",
    "\n",
    "#Quick trial run\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    LSTM_model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X_batch = X_batch.unsqueeze(-1).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = LSTM_model(X_batch)\n",
    "\n",
    "        #Calculate loss\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #Update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        #Track loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "049d9302-d629-4a8d-9d96-9bb22c01014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|███████████████████████████| 8736/8736 [00:26<00:00, 329.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 4.1954498291015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation loop\n",
    "#Metrics tracking\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "LSTM_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X_batch = X_batch.unsqueeze(-1).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = LSTM_model(X_batch)\n",
    "\n",
    "        mse(outputs.squeeze(), y_batch)\n",
    "\n",
    "print(f\"Test MSE: {mse.compute()}\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa359551-a212-4162-bddc-86b4e173abb7",
   "metadata": {},
   "source": [
    "#### III. GRU\n",
    "Gated Recurrent Unit (simplified version of LSTM cell)\n",
    "1. **Forget gate**\n",
    "2. **Input gate**\n",
    "\n",
    "**Important to remember**: No output gate and just one hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8e03b15e-6ddb-4074-96b1-063960bb2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code below is almost identical to RNN > we replace nn.RNN with nn.GRU\n",
    "\n",
    "#Define GRU\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = 1,\n",
    "            hidden_size = 32,\n",
    "            num_layers = 2,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bd362ff8-a66d-4431-b157-fe181dde8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "GRU_model = GRU()\n",
    "\n",
    "#Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.Adam(GRU_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d6f51182-cb75-4097-af85-8570ab35228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████████████████████| 26280/26280 [08:08<00:00, 53.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 6.2439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Device set-up\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GRU_model = GRU_model.to(device)\n",
    "\n",
    "#Quick trial run\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #Set to training mode\n",
    "    GRU_model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X_batch = X_batch.unsqueeze(-1).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = GRU_model(X_batch)\n",
    "\n",
    "        #Calculate loss\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #Update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        #Track loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6cc64446-a4a6-401e-914d-1cf9442df2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|███████████████████████████| 8736/8736 [00:26<00:00, 332.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 4.2448344230651855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation loop\n",
    "#Metrics tracking\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "GRU_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        X_batch = X_batch.unsqueeze(-1).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = GRU_model(X_batch)\n",
    "\n",
    "        mse(outputs.squeeze(), y_batch)\n",
    "\n",
    "print(f\"Test MSE: {mse.compute()}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c47d9-3481-4be0-9cd7-852dee245d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
